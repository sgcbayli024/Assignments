{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuHOVEV/PxpZyC4Zvar06r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgcbayli024/Assignments/blob/main/Conor_Bayliss_Assignment_4_incomplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, let us import the code from the provided file dp_algos.py"
      ],
      "metadata": {
        "id": "Giagxs6SxOX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install quantecon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_MoBqe370qa",
        "outputId": "0671bb1a-31ef-4419-ded5-9cfe0e572bb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quantecon\n",
            "  Downloading quantecon-0.7.1-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.8/214.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.49.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (0.56.4)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from quantecon) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.11.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from quantecon) (1.12)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.0->quantecon) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.0->quantecon) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->quantecon) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->quantecon) (1.3.0)\n",
            "Installing collected packages: quantecon\n",
            "Successfully installed quantecon-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jnSYfYfnxKE_"
      },
      "outputs": [],
      "source": [
        "import jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "TPdTiR4M44bl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "izjXJGEt7xhP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import quantecon as qe\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from numba import njit, prange, int32"
      ],
      "metadata": {
        "id": "0o_kW14y7znJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value Function Iteration"
      ],
      "metadata": {
        "id": "_FdVgt7R4_Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def value_function_iteration(v_init,\n",
        "                             T,\n",
        "                             get_greedy,\n",
        "                             tolerance=1e-6,        # Error tolerance\n",
        "                             max_iter=10_000,       # Max iteration bound\n",
        "                             print_step=25,         # Print at multiples\n",
        "                             verbose=True,\n",
        "                             usejax=False):\n",
        "    \"\"\"\n",
        "        Compute v_star via VFI and then compute greedy.\n",
        "    \"\"\"\n",
        "    array_lib = jnp if usejax else np\n",
        "\n",
        "    v = v_init\n",
        "    error = tolerance + 1\n",
        "    k = 1\n",
        "    while error > tolerance and k <= max_iter:\n",
        "        v_new = T(v)\n",
        "        error = array_lib.max(array_lib.abs(v_new - v))\n",
        "        if verbose and (k % print_step) == 0:\n",
        "            print(f\"Completed iteration {k} with error {error}.\")\n",
        "        v = v_new\n",
        "        k += 1\n",
        "    if error > tolerance:\n",
        "        print(f\"Warning: Iteration hit upper bound {max_iter}.\")\n",
        "    elif verbose:\n",
        "        print(f\"Terminated successfully in {k} iterations.\")\n",
        "    v_star = v\n",
        "    σ_star = get_greedy(v_star)\n",
        "    return v_star, σ_star"
      ],
      "metadata": {
        "id": "enQLCPMP445D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimistic Policy Iteration"
      ],
      "metadata": {
        "id": "EaDxslLW5Cbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimistic_policy_iteration(v_init,\n",
        "                                T_σ,\n",
        "                                get_greedy,\n",
        "                                tolerance=1e-6,\n",
        "                                max_iter=1_000,\n",
        "                                print_step=10,\n",
        "                                m=60,\n",
        "                                usejax=False):\n",
        "    \"Optimistic policy iteration routine.\"\n",
        "\n",
        "    array_lib = jnp if usejax else np\n",
        "    v = v_init\n",
        "    error = tolerance + 1\n",
        "    k = 1\n",
        "    while error > tolerance and k < max_iter:\n",
        "        last_v = v\n",
        "        σ = get_greedy(v)\n",
        "        for i in range(m):\n",
        "            v = T_σ(v, σ)\n",
        "        error = array_lib.max(array_lib.abs(v - last_v))\n",
        "        if k % print_step == 0:\n",
        "            print(f\"Completed iteration {k} with error {error}.\")\n",
        "        k += 1\n",
        "    return v, get_greedy(v)"
      ],
      "metadata": {
        "id": "pnlx-6Se48Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Howard Policy Iteration"
      ],
      "metadata": {
        "id": "z876VpeL5E-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def howard_policy_iteration(v_init,\n",
        "                            get_value,\n",
        "                            get_greedy,\n",
        "                            usejax=False):\n",
        "    \"Howard policy iteration routine.\"\n",
        "    array_lib = jnp if usejax else np\n",
        "\n",
        "    σ = get_greedy(v_init)\n",
        "    i, error = 0, 1.0\n",
        "    while error > 0:\n",
        "        v_σ = get_value(σ)\n",
        "        σ_new = get_greedy(v_σ)\n",
        "        error = array_lib.max(array_lib.abs(σ_new - σ))\n",
        "        σ = σ_new\n",
        "        i = i + 1\n",
        "        print(f\"Concluded loop {i} with error {error}.\")\n",
        "    return v_σ, σ"
      ],
      "metadata": {
        "id": "oTvRDMlt49DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let us import the code from the provided file model.py. Note that I have added @jax.jit to all function definitions."
      ],
      "metadata": {
        "id": "k6v7ut595JPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def f(y, a, d):\n",
        "    \" Inventory update rule. \"\n",
        "    return np.maximum(y - d, 0) + a"
      ],
      "metadata": {
        "id": "VG_Vmx685Q8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NamedTuple to hold model parameters\n",
        "Params = namedtuple(\n",
        "         \"Params\", (\"K\", \"c\", \"κ\", \"p\"))"
      ],
      "metadata": {
        "id": "6aMXaRNp5SX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def build_R(params, y_vals, d_vals, ϕ_vals):\n",
        "    \" Build the R array using loops. \"\n",
        "    K, c, κ, p = params\n",
        "    n_y = K + 1\n",
        "    R = np.zeros((n_y, n_y, n_y))\n",
        "    for y in y_vals:\n",
        "        for yp in y_vals:\n",
        "            for a in range(n_y - y):\n",
        "                hits = f(y, a, d_vals) == yp\n",
        "                R[y, a, yp] = np.sum(hits * ϕ_vals)\n",
        "    return R"
      ],
      "metadata": {
        "id": "gMkIq_PX5TW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def build_R_vectorized(params, y_vals, d_vals, ϕ_vals):\n",
        "    K, c, κ, p = params\n",
        "    n_y = K + 1\n",
        "    n_d = len(d_vals)\n",
        "    # Create R[y, a, yp, d] and then sum out last dimension\n",
        "    y  = np.reshape(y_vals, (n_y, 1, 1, 1))\n",
        "    a  = np.reshape(y_vals, (1, n_y, 1, 1))\n",
        "    yp = np.reshape(y_vals, (1, 1, n_y, 1))\n",
        "    d  = np.reshape(d_vals, (1, 1, 1, n_d))\n",
        "    ϕ  = np.reshape(ϕ_vals, (1, 1, 1, n_d))\n",
        "    feasible = a <= K - y\n",
        "    temp = (f(y, a, d_vals) == yp) * feasible\n",
        "    R = np.sum(temp * ϕ_vals, axis=3)\n",
        "    return R"
      ],
      "metadata": {
        "id": "q8xKtwm25WSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def build_r(params, y_vals, d_vals, ϕ_vals):\n",
        "    K, c, κ, p = params\n",
        "    n_y = K + 1\n",
        "    r = np.full((n_y, n_y), -np.inf)\n",
        "    for y in y_vals:\n",
        "        revenue = np.sum(np.minimum(y, d_vals) * ϕ_vals)\n",
        "        for a in range(n_y - y):\n",
        "            cost = c * a + κ * (a > 0)\n",
        "            r[y, a] = revenue - cost\n",
        "    return r"
      ],
      "metadata": {
        "id": "zBK3wBQQ5Y1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def build_r_vectorized(params, y_vals, d_vals, ϕ_vals):\n",
        "    K, c, κ, p = params\n",
        "    n_y = K + 1\n",
        "    n_d = len(d_vals)\n",
        "    y = np.reshape(y_vals, (n_y, 1))\n",
        "    d = np.reshape(d_vals, (1, n_d))\n",
        "    ϕ = np.reshape(ϕ_vals, (1, n_d))\n",
        "    revenue = np.minimum(y, d) * ϕ\n",
        "    exp_revenue = np.sum(revenue, axis=1)\n",
        "    exp_revenue = np.reshape(exp_revenue, (n_y, 1))\n",
        "    a = np.reshape(y_vals, (1, n_y))\n",
        "    cost = c * a + κ * (a > 0)\n",
        "    exp_profit = exp_revenue - cost\n",
        "    feasible = a <= K - y\n",
        "    r = np.where(feasible, exp_profit, -np.inf)\n",
        "    return r"
      ],
      "metadata": {
        "id": "T5Ojg0mA5kxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NamedTuple to hold arrays used to solve model\n",
        "Arrays = namedtuple(\n",
        "         \"Arrays\", (\"r\", \"R\", \"y_vals\", \"z_vals\", \"Q\"))"
      ],
      "metadata": {
        "id": "fvZFUhsh5vI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NamedTuple to store parameters, array sizes, and arrays\n",
        "Model = namedtuple(\"Model\", (\"params\", \"sizes\", \"arrays\"))"
      ],
      "metadata": {
        "id": "bdto7O355vlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def create_sdd_inventory_model(ρ=0.98,        # Z persistence\n",
        "                               ν=0.002,       # Z volatility\n",
        "                               n_z=25,        # size of Z grid\n",
        "                               b=0.97,        # Z mean\n",
        "                               K=100,         # max inventory\n",
        "                               d_max=100,     # max value of d\n",
        "                               c=0.2,         # unit cost\n",
        "                               κ=0.8,         # fixed cost\n",
        "                               p=0.6):        # demand parameter\n",
        "\n",
        "    n_y = K + 1               # size of state space\n",
        "    y_vals = np.arange(n_y)   # inventory levels 0,...,K\n",
        "\n",
        "    # Construct r and R arrays\n",
        "    def ϕ(d):\n",
        "        return (1 - p)**d * p\n",
        "    d_vals = np.arange(d_max)\n",
        "    ϕ_vals = ϕ(d_vals)\n",
        "\n",
        "    # Build the exogenous discount process\n",
        "    mc = qe.tauchen(n_z, ρ, ν)\n",
        "    z_vals, Q = mc.state_values + b, mc.P\n",
        "    ρL = np.max(np.abs(np.linalg.eigvals(z_vals * Q)))\n",
        "    if ρL >= 1:\n",
        "        raise NotImplementedError(\"Error: ρ(L) ≥ 1.\")\n",
        "    else:\n",
        "        print(f\"Building model with ρ(L) = {ρL}\")\n",
        "\n",
        "    # Build namedtuples and return them\n",
        "    params = Params(K=K, c=c, κ=κ, p=p)\n",
        "    r = build_r_vectorized(params, y_vals, d_vals, ϕ_vals)\n",
        "    R = build_R_vectorized(params, y_vals, d_vals, ϕ_vals)\n",
        "\n",
        "    arrays = Arrays(r=r, R=R, y_vals=y_vals, z_vals=z_vals, Q=Q)\n",
        "    sizes = n_y, n_z\n",
        "    return Model(params=params, sizes=sizes, arrays=arrays)"
      ],
      "metadata": {
        "id": "zuJUVPss5xpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, import the code from the file plot_code.py"
      ],
      "metadata": {
        "id": "XfuwVcLR55er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def sim_inventories(model, σ_star, ts_length, Y_init=0, seed=500):\n",
        "    \"\"\"\n",
        "        Simulate inventory dynamics and interest rates given an\n",
        "        optimal policy σ_star.\n",
        "    \"\"\"\n",
        "    # Set up\n",
        "    np.random.seed(seed)\n",
        "    K, c, κ, p = model.params\n",
        "    r, R, y_vals, z_vals, Q = model.arrays\n",
        "\n",
        "    # Generate Markov chain for discount factor\n",
        "    z_mc = qe.MarkovChain(Q, z_vals)\n",
        "    i_z = z_mc.simulate_indices(ts_length, init=1, random_state=seed)\n",
        "\n",
        "    # Generate corresponding inventory series\n",
        "    Y = np.zeros(ts_length, dtype=int)\n",
        "    Y[0] = Y_init\n",
        "    for t in range(ts_length - 1):\n",
        "        D = np.random.geometric(p) - 1\n",
        "        a = σ_star[Y[t], i_z[t]]\n",
        "        Y[t+1] = f(Y[t],  a,  D)\n",
        "\n",
        "    # Return both series\n",
        "    return Y, z_vals[i_z]"
      ],
      "metadata": {
        "id": "-yKrEjaz5_i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def plot_ts(model,\n",
        "            σ_star,\n",
        "            ts_length=400,\n",
        "            fontsize=12,\n",
        "            figname=\"ts.pdf\",\n",
        "            savefig=False):\n",
        "    \"\"\"\n",
        "        Solve model, plot a time series of inventory and interest rates.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtain inventory and discount factor series\n",
        "    Y, Z = sim_inventories(model, σ_star, ts_length)\n",
        "    r = (1 / Z) - 1 # calculate interest rate from discount factors\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(9, 5.5))\n",
        "    ax = axes[0]\n",
        "    ax.plot(Y, label=\"inventory\", alpha=0.7)\n",
        "    ax.set_xlabel(\"time\", fontsize=fontsize)\n",
        "    ax.legend(fontsize=fontsize, frameon=False)\n",
        "    ax.set_ylim(0, np.max(Y)+3)\n",
        "    ax = axes[1]\n",
        "    ax.plot(r, label=\"$r_t$\", alpha=0.7)\n",
        "    ax.set_xlabel(\"$t$\", fontsize=fontsize)\n",
        "    ax.legend(fontsize=fontsize, frameon=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    if savefig:\n",
        "        fig.savefig(figname)"
      ],
      "metadata": {
        "id": "eVzKsS515_dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def plot_timing(hpi_time,\n",
        "                vfi_time,\n",
        "                opi_times,\n",
        "                m_vals,\n",
        "                figname=\"timing.pdf\",\n",
        "                fontsize=12,\n",
        "                savefig=False):\n",
        "    \"\"\"\n",
        "    Plot relative timing of different algorithms.\n",
        "\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(9, 5.2))\n",
        "\n",
        "    y_values = (np.full(len(m_vals), vfi_time),\n",
        "                np.full(len(m_vals), hpi_time),\n",
        "                opi_times)\n",
        "    labels = \"VFI\", \"HPI\", \"OPI\"\n",
        "\n",
        "    for y_vals, label in zip(y_values, labels):\n",
        "        ax.plot(m_vals, y_vals, lw=2, label=label)\n",
        "\n",
        "    ax.legend(fontsize=fontsize, frameon=False)\n",
        "    ax.set_xlabel(\"$m$\", fontsize=fontsize)\n",
        "    ax.set_ylabel(\"time\", fontsize=fontsize)\n",
        "    plt.show()\n",
        "\n",
        "    if savefig:\n",
        "        fig.savefig(figname)"
      ],
      "metadata": {
        "id": "6jM8jtgo6Hd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = jax.jit(f)"
      ],
      "metadata": {
        "id": "yr5kQCex6O9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def B(y, i_z, a, v, model):\n",
        "    \"\"\"\n",
        "    B(y, a, v) = r(y, a) + β(z) Σ_{y′, z′} v(y′, z′) R(y, a, y′) Q(z, z′)\n",
        "\n",
        "    Jax implementation\n",
        "    \"\"\"\n",
        "    # Set up\n",
        "    K, c, κ, p = model.params\n",
        "    r, R, y_vals, z_vals, Q = model.arrays\n",
        "    β = z_vals[i_z]\n",
        "    I, J =len(y_vals) , len(z_vals)\n",
        "    N = I * J\n",
        "    #Reshape and broadcast over (i, j, i', j')\n",
        "\n",
        "    #Reshape and broadcast over (y, a, y', z, z')\n",
        "    Q  = jnp.reshape(Q, (1, 1, 1, J, J))\n",
        "    R  = jnp.reshape(R, (I, I, I, 1, 1))\n",
        "    v  = jnp.reshape(v, (1, 1, I, 1, J))\n",
        "    EV = jnp.sum(v*R*Q, axis=(2, 4))\n",
        "    #Now, reshape and broadcast over  (y ,a ,z)\n",
        "    β  = jnp.reshape(β, (1, 1, J))\n",
        "    r  = jnp.reshape(r, (I, I, 1))\n",
        "    B  = r + β * EV\n",
        "    return B"
      ],
      "metadata": {
        "id": "fatNSw1D6Pac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_r_σ(σ, model):\n",
        "    \"\"\"\n",
        "    Compute the array r_σ[i, j] = r[i, j, σ[i, j]], which gives current\n",
        "    rewards given policy σ.\n",
        "    \"\"\"\n",
        "\n",
        "    # Unpack model\n",
        "    K, c, κ, p = model.params\n",
        "    r, R, y_vals, z_vals, Q = model.arrays\n",
        "    z_idx=jnp.arange(z_vals)\n",
        "    I, J =len(y_vals) , len(z_vals)\n",
        "    N = I * J\n",
        "    # Compute r_σ[i, j]\n",
        "    y = jnp.reshape(y_vals, (I, 1))\n",
        "    z = jnp.reshape(z_idx, (1, J))\n",
        "    r_σ = r[y, σ[y,z]]\n",
        "\n",
        "    return r_σ"
      ],
      "metadata": {
        "id": "aO9Wg_LZ6eSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_R_σ(σ, model):\n",
        "    \"\"\"\n",
        "    Compute the array r_σ[i, j] = r[i, j, σ[i, j]], which gives current\n",
        "    rewards given policy σ.\n",
        "    \"\"\"\n",
        "\n",
        "    # Unpack model\n",
        "    K, c, κ, p = model.params\n",
        "    r, R, y_vals, z_vals, Q = model.arrays\n",
        "    z_idx=jnp.arange(z_vals)\n",
        "    I, J =len(y_vals) , len(z_vals)\n",
        "    N = I * J\n",
        "    # Compute r_σ[i, j]\n",
        "    y = jnp.reshape(y_vals, (I, 1, 1))\n",
        "    z = jnp.reshape(z_idx, (1, J, 1))\n",
        "    yp = jnp.reshape(y_vals, (1, 1, I))\n",
        "    R_σ = R[y, σ[y,z], yp]\n",
        "\n",
        "    return R_σ"
      ],
      "metadata": {
        "id": "xM_TwrYi6gMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def T_σ(v, σ, model):\n",
        "    \"The policy operator.\"\n",
        "    K, c, κ, p = model.params\n",
        "    r, R, y_vals, z_vals, Q = model.arrays\n",
        "    n_y, n_z = model.sizes\n",
        "    I, J =len(y_vals) , len(z_vals)\n",
        "    N = I * J\n",
        "\n",
        "    r_σ=compute_r_σ(σ, model)\n",
        "\n",
        "    #Compute the array v_σ\n",
        "    yp_idx = jnp.arange(y_vals)\n",
        "    yp_idx = jnp.reshape(yp_idx, (1, 1, I))\n",
        "    σ = jnp.reshape(σ, (I, J, 1))\n",
        "    V = v[σ, yp_idx]\n",
        "\n",
        "    Q  = jnp.reshape(Q, (1, 1, 1, J, J))\n",
        "    R  = jnp.reshape(R, (I, I, I, 1, 1))\n",
        "    v  = jnp.reshape(v, (1, 1, I, 1, J))\n",
        "    Ev = jnp.sum(R*Q, axis=(2, 4))\n",
        "    EV = V * Ev\n",
        "    β  = jnp.reshape(β, (1, 1, J))\n",
        "    return r_σ + β * EV"
      ],
      "metadata": {
        "id": "0OjmmpYL6igs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def T(v, model):\n",
        "    \"\"\"The Bellman operator.\"\"\"\n",
        "    return jnp.max(B(y, i_z, a, v, model), axis=2)"
      ],
      "metadata": {
        "id": "wL75XE876lkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def get_greedy(v, constants, sizes, arrays):\n",
        "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
        "    return jnp.argmax(B(v, constants, sizes, arrays), axis=2)"
      ],
      "metadata": {
        "id": "QwmsISLv6nhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Custom solvers\n",
        "@jax.jit\n",
        "def solve_model_jax(model, algorithm=\"OPI\", **kwargs):\n",
        "    \"\"\"\n",
        "    General purpose solver.\n",
        "\n",
        "    algorithm : OPI, VFI or HPI\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up\n",
        "    n_y, n_z = model.sizes\n",
        "    v_init = jnp.zeros((n_y, n_z))\n",
        "\n",
        "    # Solve\n",
        "    print(f\"Solving model using {algorithm}.\")\n",
        "    match algorithm:\n",
        "        case \"OPI\":\n",
        "            solver = optimistic_policy_iteration\n",
        "            args = (v_init,\n",
        "                lambda v, σ: T_σ(v, σ, model),\n",
        "                lambda v: get_greedy(v, model))\n",
        "        case \"HPI\":\n",
        "            solver = howard_policy_iteration\n",
        "            args = (v_init,\n",
        "                lambda σ: get_value(σ, model),\n",
        "                lambda v: get_greedy(v, model))\n",
        "        case \"VFI\":\n",
        "            solver = value_function_iteration\n",
        "            args = (v_init,\n",
        "                lambda v: T(v, model),\n",
        "                lambda v: get_greedy(v, model))\n",
        "        case _:\n",
        "            raise ValueError(\"Algorithm must be in {OPI, VFI, HPI}\")\n",
        "\n",
        "    qe.tic()\n",
        "    v_star, σ_star = solver(*args, **kwargs)\n",
        "    run_time = qe.toc()\n",
        "    print(f\"Solved model using {algorithm} in {run_time:.5f} seconds.\")\n",
        "\n",
        "    return v_star, σ_star"
      ],
      "metadata": {
        "id": "QTryFh_W6u0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def test_timing_jax(model,\n",
        "                      m_vals=range(1, 100, 20),\n",
        "                      figname=\"numba_timing.pdf\",\n",
        "                      savefig=False):\n",
        "    \"\"\"\n",
        "    Plot relative timing of different algorithms.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    qe.tic()\n",
        "    _, σ_pi = solve_model_jax(model, algorithm=\"HPI\")\n",
        "    hpi_time = qe.toc()\n",
        "\n",
        "    qe.tic()\n",
        "    _, σ_vfi = solve_model_jax(model, algorithm=\"VFI\")\n",
        "    vfi_time = qe.toc()\n",
        "\n",
        "    error = jnp.max(jnp.abs(σ_vfi - σ_pi))\n",
        "    if error:\n",
        "        print(\"Warning: VFI policy deviated with max error {error}.\")\n",
        "\n",
        "    opi_times = []\n",
        "    for m in m_vals:\n",
        "        qe.tic()\n",
        "        _, σ_opi = solve_model_jax(model, algorithm=\"OPI\", m=m)\n",
        "        opi_times.append(qe.toc())\n",
        "\n",
        "        error = jnp.max(jnp.abs(σ_opi - σ_pi))\n",
        "        if error:\n",
        "            print(\"Warning: OPI policy deviated with max error {error}.\")\n",
        "\n",
        "    plot_timing(hpi_time,\n",
        "                vfi_time,\n",
        "                opi_times,\n",
        "                m_vals,\n",
        "                figname=figname,\n",
        "                savefig=False)\n",
        "\n",
        "    return hpi_time, vfi_time, opi_times"
      ],
      "metadata": {
        "id": "Lw-RBBXd7K0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's solve."
      ],
      "metadata": {
        "id": "s_ecRJnF7STT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_sdd_inventory_model()"
      ],
      "metadata": {
        "id": "aooD5uw77VHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Solve by VFI\n",
        "\n",
        "v_star, σ_star = solve_model_jax(model, algorithm=\"VFI\")"
      ],
      "metadata": {
        "id": "EoKgBL3Q7XP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Solve by HPI\n",
        "\n",
        "v_star, σ_star = solve_model_jax(model, algorithm=\"HPI\")"
      ],
      "metadata": {
        "id": "4rTtkUJp7aeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Solve by OPI\n",
        "\n",
        "v_star, σ_star = solve_model_jax(model, algorithm=\"OPI\")"
      ],
      "metadata": {
        "id": "L1E-RkyE7f0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_ts(model, σ_star, figname=\"jax_ts.pdf\", savefig=False)"
      ],
      "metadata": {
        "id": "v8pvgxop7iKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test timing\n",
        "\n",
        "hpi_time, vfi_time, opi_times = test_timing_jax(model)"
      ],
      "metadata": {
        "id": "UbzIp2-b7ku6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}